{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benni/.local/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import yaml\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "from densnet.model.densnet import DensNet\n",
    "from densnet.model.dumbnet import DumbNet\n",
    "from densnet.model.activations import swish\n",
    "from densnet.training.metrics import Metrics\n",
    "from densnet.training.trainer import Trainer\n",
    "from densnet.training.data_container import DataContainer\n",
    "from densnet.training.data_provider import DataProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logger\n",
    "logger = logging.getLogger()\n",
    "logger.handlers = []\n",
    "ch = logging.StreamHandler()\n",
    "formatter = logging.Formatter(\n",
    "        fmt='%(asctime)s (%(levelname)s): %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "logger.setLevel('INFO')\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "tf.get_logger().setLevel('WARN')\n",
    "tf.autograph.set_verbosity(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config_densnet.yaml', 'r') as c:\n",
    "    config = yaml.safe_load(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = config['model_name']\n",
    "\n",
    "num_basis_fct = config['num_basis_fct']\n",
    "emb_size = config['emb_size']\n",
    "num_interaction_blocks = config['num_interaction_blocks']\n",
    "ao_vals = config['ao_vals']\n",
    "num_grid_points = config['num_grid_points']\n",
    "\n",
    "num_train = config['num_train']\n",
    "num_valid = config['num_valid']\n",
    "data_seed = config['data_seed']\n",
    "dataset = config['dataset']\n",
    "logdir = config['logdir']\n",
    "\n",
    "num_steps = config['num_steps']\n",
    "ema_decay = config['ema_decay']\n",
    "\n",
    "learning_rate = config['learning_rate']\n",
    "warmup_steps = config['warmup_steps']\n",
    "decay_rate = config['decay_rate']\n",
    "decay_steps = config['decay_steps']\n",
    "\n",
    "batch_size = config['batch_size']\n",
    "evaluation_interval = config['evaluation_interval']\n",
    "save_interval = config['save_interval']\n",
    "restart = config['restart']\n",
    "comment = config['comment']\n",
    "target = config['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_container = DataContainer(dataset, target, 0.2)\n",
    "\n",
    "# Initialize DataProvider (splits dataset into training, validation and test set based on data_seed)\n",
    "data_provider = DataProvider(data_container, num_train, num_valid, batch_size,\n",
    "                             seed=data_seed, randomized=True)\n",
    "\n",
    "# Initialize datasets\n",
    "dataset = data_provider.get_dataset('test').prefetch(tf.data.experimental.AUTOTUNE)\n",
    "dataset_iter = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"dumbnet\":\n",
    "    model = DumbNet(ao_vals=ao_vals, num_interaction_blocks=num_interaction_blocks, num_grid_points=num_grid_points, activation=swish)\n",
    "else:\n",
    "    model = DensNet(ao_vals=ao_vals, num_interaction_blocks=num_interaction_blocks, num_grid_points=num_grid_points, activation=swish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, learning_rate, warmup_steps, decay_steps, decay_rate, ema_decay, max_grad_norm=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f3d79be9dc0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained model from your own training run\n",
    "files = os.listdir(\"logging\")\n",
    "rel_files = [f for f in files if model_name in f]\n",
    "rel_files.sort()\n",
    "#directory = \"logging/20230810_165359_densnet_Ael8lbyb_md_h2.npz_densities_final\"  # Fill this in\n",
    "# Get latest run\n",
    "directory = f\"logging/{rel_files[-1]}\"\n",
    "best_ckpt_file = os.path.join(directory, 'best', 'ckpt')\n",
    "model.load_weights(best_ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = Metrics('val', target)\n",
    "target_shape = data_provider.shape_target\n",
    "preds_total = np.zeros([data_provider.nsamples['test']] + target_shape[1:], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f61aa609a440d7ada3087918727294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps_per_epoch = int(np.ceil(data_provider.nsamples['test'] / batch_size) - 1)\n",
    "\n",
    "for step in tqdm(range(steps_per_epoch)):\n",
    "    preds = trainer.predict_on_batch(dataset_iter, metrics)\n",
    "\n",
    "    batch_start = step * batch_size\n",
    "    batch_end = min((step + 1) * batch_size, data_provider.nsamples['test'])\n",
    "    preds_total[batch_start:batch_end] = preds.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_log_file = os.path.join(directory, 'preds.npz')\n",
    "log_dict = {}\n",
    "log_dict[\"MAE\"] = metrics.mean_mae\n",
    "log_dict[\"logMAE\"] = metrics.mean_log_mae\n",
    "log_dict[\"pred_densities\"] = preds_total\n",
    "log_dict[\"data_idx\"] = data_provider.idx['test']\n",
    "pickle.dump(log_dict, open(preds_log_file, \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantchem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
