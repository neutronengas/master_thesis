{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benni/anaconda3/envs/tf_old/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/Users/benni/anaconda3/envs/tf_old/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.11.0 and strictly below 2.14.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import yaml\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from densnet.model.densnet import DensNet\n",
    "from densnet.model.dumbnet import DumbNet\n",
    "from densnet.model.activations import swish\n",
    "from densnet.training.metrics import Metrics\n",
    "from densnet.training.trainer import Trainer\n",
    "from densnet.training.data_container import DataContainer\n",
    "from densnet.training.data_provider import DataProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logger\n",
    "logger = logging.getLogger()\n",
    "logger.handlers = []\n",
    "ch = logging.StreamHandler()\n",
    "formatter = logging.Formatter(\n",
    "        fmt='%(asctime)s (%(levelname)s): %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "logger.setLevel('INFO')\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "tf.get_logger().setLevel('WARN')\n",
    "tf.autograph.set_verbosity(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config_densnet.yaml', 'r') as c:\n",
    "    config = yaml.safe_load(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = config['model_name']\n",
    "\n",
    "s_type_per_atom = config['s_type_per_atom']\n",
    "p_type_per_atom = config['p_type_per_atom']\n",
    "emb_size = config['emb_size']\n",
    "num_interaction_blocks = config['num_interaction_blocks']\n",
    "width_ticks = config['width_ticks']\n",
    "length_ticks = config['length_ticks']\n",
    "cutoff = config['cutoff']\n",
    "\n",
    "num_train = config['num_train']\n",
    "num_valid = config['num_valid']\n",
    "data_seed = config['data_seed']\n",
    "dataset = config['dataset']\n",
    "logdir = config['logdir']\n",
    "\n",
    "num_steps = config['num_steps']\n",
    "ema_decay = config['ema_decay']\n",
    "\n",
    "learning_rate = config['learning_rate']\n",
    "warmup_steps = config['warmup_steps']\n",
    "decay_rate = config['decay_rate']\n",
    "decay_steps = config['decay_steps']\n",
    "\n",
    "batch_size = config['batch_size']\n",
    "evaluation_interval = config['evaluation_interval']\n",
    "save_interval = config['save_interval']\n",
    "restart = config['restart']\n",
    "comment = config['comment']\n",
    "target = config['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 11:57:25.344536: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "data_container = DataContainer(dataset, target, 0.2)\n",
    "\n",
    "# Initialize DataProvider (splits dataset into training, validation and test set based on data_seed)\n",
    "data_provider = DataProvider(data_container, num_train, num_valid, batch_size,\n",
    "                             seed=data_seed, randomized=True)\n",
    "\n",
    "# Initialize datasets\n",
    "dataset = data_provider.get_dataset('test').prefetch(tf.data.experimental.AUTOTUNE)\n",
    "dataset_iter = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"dumbnet\":\n",
    "    model = None\n",
    "else:\n",
    "    model = DensNet(num_interaction_blocks=num_interaction_blocks, num_grid_points=width_ticks*length_ticks, emb_size=emb_size, s_type_per_atom=s_type_per_atom, p_type_per_atom=p_type_per_atom, activation=swish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, learning_rate, warmup_steps, decay_steps, decay_rate, ema_decay, max_grad_norm=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1064c3100>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained model from your own training run\n",
    "files = os.listdir(\"logging\")\n",
    "rel_files = [f for f in files if model_name in f]\n",
    "rel_files.sort()\n",
    "#directory = \"logging/20230810_165359_densnet_Ael8lbyb_md_h2.npz_densities_final\"  # Fill this in\n",
    "# Get latest run\n",
    "directory = f\"logging/{rel_files[-1]}\"\n",
    "best_ckpt_file = os.path.join(directory, 'best', 'ckpt')\n",
    "model.load_weights(best_ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = Metrics('val', target)\n",
    "target_shape = data_provider.shape_target\n",
    "preds_total = np.zeros([data_provider.nsamples['test']] + target_shape[1:], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2416fb0fda4e99af305a6e213eb1ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps_per_epoch = int(np.ceil(data_provider.nsamples['test'] / batch_size) - 1)\n",
    "\n",
    "for step in tqdm(range(steps_per_epoch)):\n",
    "    preds = trainer.predict_on_batch(dataset_iter, metrics)\n",
    "\n",
    "    batch_start = step * batch_size\n",
    "    batch_end = min((step + 1) * batch_size, data_provider.nsamples['test'])\n",
    "    preds_total[batch_start:batch_end] = preds.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_log_file = os.path.join(directory, 'preds.npz')\n",
    "log_dict = {}\n",
    "log_dict[\"MAE\"] = metrics.mean_mae\n",
    "log_dict[\"logMAE\"] = metrics.mean_log_mae\n",
    "log_dict[\"pred_densities\"] = preds_total\n",
    "log_dict[\"data_idx\"] = data_provider.idx['test']\n",
    "pickle.dump(log_dict, open(preds_log_file, \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantchem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
